{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a26c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID Lookalike1_ID  Lookalike1_Score Lookalike2_ID  Lookalike2_Score  \\\n",
      "0       C0001         C0096            0.9785         C0113            0.9169   \n",
      "1       C0002         C0088            0.9924         C0078            0.9631   \n",
      "2       C0003         C0012            0.9832         C0155            0.9729   \n",
      "3       C0004         C0108            0.9026         C0099            0.8606   \n",
      "4       C0005         C0128            0.9983         C0021            0.9479   \n",
      "5       C0006         C0011            0.9597         C0095            0.9048   \n",
      "6       C0007         C0162            0.9507         C0093            0.9484   \n",
      "7       C0008         C0038            0.9744         C0030            0.9733   \n",
      "8       C0009         C0069            0.9550         C0057            0.8876   \n",
      "9       C0010         C0100            0.9741         C0069            0.9128   \n",
      "10      C0011         C0188            0.9653         C0006            0.9597   \n",
      "11      C0012         C0155            0.9980         C0171            0.9911   \n",
      "12      C0013         C0153            0.9228         C0003            0.9210   \n",
      "13      C0014         C0141            0.9872         C0074            0.9386   \n",
      "14      C0015         C0055            0.9984         C0185            0.9941   \n",
      "15      C0016         C0029            0.9895         C0154            0.9784   \n",
      "16      C0017         C0119            0.9394         C0167            0.9317   \n",
      "17      C0018         C0160            0.9893         C0047            0.9768   \n",
      "18      C0019         C0041            0.9794         C0023            0.9571   \n",
      "\n",
      "   Lookalike3_ID  Lookalike3_Score  \n",
      "0          C0076            0.9128  \n",
      "1          C0159            0.9622  \n",
      "2          C0195            0.9615  \n",
      "3          C0158            0.8347  \n",
      "4          C0159            0.8403  \n",
      "5          C0108            0.8952  \n",
      "6          C0027            0.9314  \n",
      "7          C0117            0.9604  \n",
      "8          C0051            0.8848  \n",
      "9          C0127            0.8969  \n",
      "10         C0192            0.9547  \n",
      "11         C0195            0.9884  \n",
      "12         C0052            0.9176  \n",
      "13         C0132            0.9284  \n",
      "14         C0033            0.9783  \n",
      "15         C0139            0.9073  \n",
      "16         C0014            0.9125  \n",
      "17         C0131            0.9163  \n",
      "18         C0182            0.9456  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_customer_data(df):\n",
    "    \"\"\"Clean and prepare customer data\"\"\"\n",
    " \n",
    "    df.columns = ['CustomerID', 'CustomerName', 'Region', 'SignupDate']\n",
    "\n",
    "    df['Region'] = df['Region'].str.strip()\n",
    "\n",
    "    df['SignupDate'] = pd.to_datetime(df['SignupDate'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_product_data(df):\n",
    "    \"\"\"Clean and prepare product data\"\"\"\n",
    "\n",
    "    df.columns = ['ProductID', 'ProductName', 'Category', 'Price']\n",
    "    \n",
    "\n",
    "    df['Category'] = df['Category'].str.strip()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_and_prepare_data(customers_file, products_file):\n",
    "    \"\"\"Load and prepare the data for the lookalike model\"\"\"\n",
    "\n",
    "    customers = pd.read_csv(r\"C:\\Users\\rahul\\Downloads\\Data_Science\\Customers.csv\")\n",
    "    products = pd.read_csv(r\"C:\\Users\\rahul\\Downloads\\Data_Science\\Products.csv\")\n",
    "    \n",
    "\n",
    "    customers = clean_customer_data(customers)\n",
    "    products = clean_product_data(products)\n",
    "\n",
    "    region_dummies = pd.get_dummies(customers['Region'], prefix='Region')\n",
    "    \n",
    "\n",
    "    n_categories = len(products['Category'].unique())\n",
    "    category_preferences = pd.DataFrame(\n",
    "        np.random.dirichlet(np.ones(n_categories), size=len(customers)),\n",
    "        columns=products['Category'].unique(),\n",
    "        index=customers.index\n",
    "    )\n",
    "\n",
    "    feature_df = pd.concat([\n",
    "        customers[['CustomerID']],\n",
    "        region_dummies,\n",
    "        category_preferences\n",
    "    ], axis=1)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "def create_lookalike_model(feature_df):\n",
    "    \"\"\"Create and return the lookalike model\"\"\"\n",
    "    # Separate CustomerID and features\n",
    "    customer_ids = feature_df['CustomerID']\n",
    "    features = feature_df.drop('CustomerID', axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "\n",
    "    similarity_matrix = cosine_similarity(scaled_features)\n",
    "    \n",
    "    return customer_ids, similarity_matrix\n",
    "\n",
    "def get_top_lookalikes(customer_id, customer_ids, similarity_matrix, n=3):\n",
    "    \"\"\"Get top n lookalike customers for a given customer ID\"\"\"\n",
    "\n",
    "    customer_idx = customer_ids[customer_ids == customer_id].index[0]\n",
    "    \n",
    "\n",
    "    similarities = similarity_matrix[customer_idx]\n",
    "    \n",
    "\n",
    "    similar_indices = np.argsort(similarities)[::-1][1:n+1]\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    for idx in similar_indices:\n",
    "        results.append({\n",
    "            'customer_id': customer_ids.iloc[idx],\n",
    "            'similarity_score': similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_lookalike_recommendations():\n",
    "    \"\"\"Generate lookalike recommendations for customers C0001-C0020\"\"\"\n",
    "\n",
    "    feature_df = load_and_prepare_data('Customers.csv', 'Products.csv')\n",
    "    customer_ids, similarity_matrix = create_lookalike_model(feature_df)\n",
    "    \n",
    "\n",
    "    recommendations = []\n",
    "    for customer_id in customer_ids[customer_ids.str.match('C00[0-1][0-9]')]:\n",
    "        lookalikes = get_top_lookalikes(customer_id, customer_ids, similarity_matrix)\n",
    "        row = {\n",
    "            'CustomerID': customer_id,\n",
    "            'Lookalike1_ID': lookalikes[0]['customer_id'],\n",
    "            'Lookalike1_Score': round(lookalikes[0]['similarity_score'], 4),\n",
    "            'Lookalike2_ID': lookalikes[1]['customer_id'],\n",
    "            'Lookalike2_Score': round(lookalikes[1]['similarity_score'], 4),\n",
    "            'Lookalike3_ID': lookalikes[2]['customer_id'],\n",
    "            'Lookalike3_Score': round(lookalikes[2]['similarity_score'], 4)\n",
    "        }\n",
    "        recommendations.append(row)\n",
    "    \n",
    "\n",
    "    result_df = pd.DataFrame(recommendations)\n",
    "    result_df.to_csv('FirstName_LastName_Lookalike.csv', index=False)\n",
    "    return result_df\n",
    "recommendations = generate_lookalike_recommendations()\n",
    "print(recommendations)\n",
    "recommendations.to_csv(r\"C:\\Users\\rahul\\Downloads\\Data_Science\\Rahul_Gurram_Lookalike.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c0e3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lookalike Recommendations:\n",
      "   CustomerID Lookalike1_ID  Lookalike1_Score Lookalike2_ID  Lookalike2_Score  \\\n",
      "0       C0001         C0032            0.9899         C0102            0.9868   \n",
      "1       C0002         C0200            0.9743         C0093            0.9607   \n",
      "2       C0003         C0004            0.9713         C0095            0.9577   \n",
      "3       C0004         C0130            0.9854         C0003            0.9713   \n",
      "4       C0005         C0045            0.9860         C0159            0.9780   \n",
      "5       C0006         C0104            0.9985         C0188            0.9823   \n",
      "6       C0007         C0101            0.9744         C0173            0.9278   \n",
      "7       C0008         C0068            0.9782         C0034            0.9197   \n",
      "8       C0009         C0023            0.9940         C0172            0.9828   \n",
      "9       C0010         C0121            0.9698         C0014            0.9154   \n",
      "10      C0011         C0152            0.9422         C0113            0.9361   \n",
      "11      C0012         C0120            0.9702         C0013            0.9373   \n",
      "12      C0013         C0181            0.9963         C0195            0.9806   \n",
      "13      C0014         C0105            0.9811         C0037            0.9741   \n",
      "14      C0015         C0024            0.9878         C0131            0.9703   \n",
      "15      C0016         C0035            0.9964         C0157            0.9564   \n",
      "16      C0017         C0051            0.9897         C0066            0.9756   \n",
      "17      C0018         C0185            0.9946         C0117            0.9469   \n",
      "18      C0019         C0074            0.9766         C0167            0.9758   \n",
      "\n",
      "   Lookalike3_ID  Lookalike3_Score  \n",
      "0          C0190            0.9500  \n",
      "1          C0178            0.9317  \n",
      "2          C0083            0.9542  \n",
      "3          C0169            0.9629  \n",
      "4          C0161            0.9710  \n",
      "5          C0048            0.9720  \n",
      "6          C0027            0.9272  \n",
      "7          C0055            0.8720  \n",
      "8          C0064            0.9690  \n",
      "9          C0086            0.9056  \n",
      "10         C0150            0.8889  \n",
      "11         C0181            0.9263  \n",
      "12         C0082            0.9781  \n",
      "13         C0121            0.9556  \n",
      "14         C0072            0.9637  \n",
      "15         C0026            0.9441  \n",
      "16         C0119            0.9493  \n",
      "17         C0046            0.9307  \n",
      "18         C0199            0.9738  \n",
      "\n",
      "Model Evaluation Results:\n",
      "\n",
      "1. Similarity Score Distribution:\n",
      "mean_similarity: 0.0002\n",
      "std_similarity: 0.4147\n",
      "min_similarity: -0.7228\n",
      "max_similarity: 1.0000\n",
      "\n",
      "2. Region Cohesion Score: 1.0000\n",
      "\n",
      "3. Category Preference Analysis:\n",
      "mean_correlation: 0.4999\n",
      "max_correlation: 0.3694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def clean_customer_data(df):\n",
    "    \"\"\"Clean and prepare customer data\"\"\"\n",
    "    df.columns = ['CustomerID', 'CustomerName', 'Region', 'SignupDate']\n",
    "    df['Region'] = df['Region'].str.strip()\n",
    "    df['SignupDate'] = pd.to_datetime(df['SignupDate'])\n",
    "    return df\n",
    "\n",
    "def clean_product_data(df):\n",
    "    \"\"\"Clean and prepare product data\"\"\"\n",
    "    df.columns = ['ProductID', 'ProductName', 'Category', 'Price']\n",
    "    df['Category'] = df['Category'].str.strip()\n",
    "    return df\n",
    "\n",
    "def load_and_prepare_data(customers_file, products_file):\n",
    "    \"\"\"Load and prepare the data for the lookalike model\"\"\"\n",
    "\n",
    "    customers = pd.read_csv(r\"C:\\Users\\rahul\\Downloads\\Data_Science\\Customers.csv\")\n",
    "    products = pd.read_csv(r\"C:\\Users\\rahul\\Downloads\\Data_Science\\Products.csv\")\n",
    "    \n",
    "\n",
    "    customers = clean_customer_data(customers)\n",
    "    products = clean_product_data(products)\n",
    "    \n",
    "\n",
    "    region_dummies = pd.get_dummies(customers['Region'], prefix='Region')\n",
    "\n",
    "    n_categories = len(products['Category'].unique())\n",
    "    category_preferences = pd.DataFrame(\n",
    "        np.random.dirichlet(np.ones(n_categories), size=len(customers)),\n",
    "        columns=products['Category'].unique(),\n",
    "        index=customers.index\n",
    "    )\n",
    "    \n",
    "\n",
    "    feature_df = pd.concat([\n",
    "        customers[['CustomerID']],\n",
    "        region_dummies,\n",
    "        category_preferences\n",
    "    ], axis=1)\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def create_lookalike_model(feature_df):\n",
    "    \"\"\"Create and return the lookalike model\"\"\"\n",
    "    customer_ids = feature_df['CustomerID']\n",
    "    features = feature_df.drop('CustomerID', axis=1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(scaled_features)\n",
    "    \n",
    "    return customer_ids, similarity_matrix\n",
    "\n",
    "\n",
    "def get_top_lookalikes(customer_id, customer_ids, similarity_matrix, n=3):\n",
    "    \"\"\"Get top n lookalike customers for a given customer ID\"\"\"\n",
    "    customer_idx = customer_ids[customer_ids == customer_id].index[0]\n",
    "    similarities = similarity_matrix[customer_idx]\n",
    "    \n",
    "    similar_indices = np.argsort(similarities)[::-1][1:n+1]\n",
    "    \n",
    "    results = []\n",
    "    for idx in similar_indices:\n",
    "        results.append({\n",
    "            'customer_id': customer_ids.iloc[idx],\n",
    "            'similarity_score': similarities[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_lookalike_recommendations():\n",
    "    \"\"\"Generate lookalike recommendations for customers C0001-C0020\"\"\"\n",
    "    feature_df = load_and_prepare_data('Customers.csv', 'Products.csv')\n",
    "    customer_ids, similarity_matrix = create_lookalike_model(feature_df)\n",
    "    \n",
    "    recommendations = []\n",
    "    for customer_id in customer_ids[customer_ids.str.match('C00[0-1][0-9]')]:\n",
    "        lookalikes = get_top_lookalikes(customer_id, customer_ids, similarity_matrix)\n",
    "        row = {\n",
    "            'CustomerID': customer_id,\n",
    "            'Lookalike1_ID': lookalikes[0]['customer_id'],\n",
    "            'Lookalike1_Score': round(lookalikes[0]['similarity_score'], 4),\n",
    "            'Lookalike2_ID': lookalikes[1]['customer_id'],\n",
    "            'Lookalike2_Score': round(lookalikes[1]['similarity_score'], 4),\n",
    "            'Lookalike3_ID': lookalikes[2]['customer_id'],\n",
    "            'Lookalike3_Score': round(lookalikes[2]['similarity_score'], 4)\n",
    "        }\n",
    "        recommendations.append(row)\n",
    "    \n",
    "    result_df = pd.DataFrame(recommendations)\n",
    "    result_df.to_csv('FirstName_LastName_Lookalike.csv', index=False)\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def analyze_region_cohesion(region_features, similarity_matrix):\n",
    "    \"\"\"Analyze if similar customers share regional characteristics\"\"\"\n",
    "    region_cohesion = []\n",
    "    \n",
    "    for i in range(len(similarity_matrix)):\n",
    "        similar_indices = np.argsort(similarity_matrix[i])[::-1][1:4]\n",
    "        customer_region = region_features.iloc[i]\n",
    "        similar_regions = region_features.iloc[similar_indices]\n",
    "        region_matches = np.mean([np.array_equal(customer_region, similar_region) \n",
    "                                for similar_region in similar_regions.values])\n",
    "        region_cohesion.append(region_matches)\n",
    "    \n",
    "    return np.mean(region_cohesion)\n",
    "\n",
    "def analyze_category_correlations(category_preferences):\n",
    "    \"\"\"Analyze correlations between category preferences\"\"\"\n",
    "    corr_matrix = category_preferences.corr()\n",
    "    return {\n",
    "        'mean_correlation': np.mean(np.abs(corr_matrix.values)),\n",
    "        'max_correlation': np.max(np.abs(corr_matrix.values[np.triu_indices_from(corr_matrix, k=1)]))\n",
    "    }\n",
    "\n",
    "def evaluate_model_quality(feature_df, similarity_matrix, customer_ids):\n",
    "    \"\"\"Evaluate the quality of the lookalike model\"\"\"\n",
    "\n",
    "    similarity_stats = {\n",
    "        'mean_similarity': np.mean(similarity_matrix),\n",
    "        'std_similarity': np.std(similarity_matrix),\n",
    "        'min_similarity': np.min(similarity_matrix[similarity_matrix != 1]),\n",
    "        'max_similarity': np.max(similarity_matrix[similarity_matrix != 1])\n",
    "    }\n",
    "    \n",
    "\n",
    "    region_cols = [col for col in feature_df.columns if col.startswith('Region_')]\n",
    "    region_validation = analyze_region_cohesion(feature_df[region_cols], similarity_matrix)\n",
    "    \n",
    "\n",
    "    category_cols = [col for col in feature_df.columns \n",
    "                    if not col.startswith('Region_') and col != 'CustomerID']\n",
    "    category_corr = analyze_category_correlations(feature_df[category_cols])\n",
    "    \n",
    "    return {\n",
    "        'similarity_stats': similarity_stats,\n",
    "        'region_validation': region_validation,\n",
    "        'category_correlation': category_corr\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    recommendations = generate_lookalike_recommendations()\n",
    "    print(\"\\nLookalike Recommendations:\")\n",
    "    print(recommendations)\n",
    "    \n",
    "\n",
    "    feature_df = load_and_prepare_data('Customers.csv', 'Products.csv')\n",
    "    customer_ids, similarity_matrix = create_lookalike_model(feature_df)\n",
    "    \n",
    "\n",
    "    evaluation_results = evaluate_model_quality(feature_df, similarity_matrix, customer_ids)\n",
    "    \n",
    "\n",
    "    print(\"\\nModel Evaluation Results:\")\n",
    "    print(\"\\n1. Similarity Score Distribution:\")\n",
    "    for metric, value in evaluation_results['similarity_stats'].items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n2. Region Cohesion Score: {evaluation_results['region_validation']:.4f}\")\n",
    "    \n",
    "    print(\"\\n3. Category Preference Analysis:\")\n",
    "    for metric, value in evaluation_results['category_correlation'].items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8205862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
